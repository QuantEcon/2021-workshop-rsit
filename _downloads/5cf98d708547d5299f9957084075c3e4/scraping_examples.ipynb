{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API\n",
    "\n",
    "https://fred.stlouisfed.org/docs/api/fred/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "FRED_URL = \"https://api.stlouisfed.org/fred\"\n",
    "\n",
    "\n",
    "def fred_series_request(series):\n",
    "    key = \"d4f97d5305ace8b756e361252fbf02cd\"\n",
    "    url = (\n",
    "        FRED_URL +\n",
    "        \"/series/observations\" +\n",
    "        f\"?series_id={series}&file_type=json&api_key={key}\"\n",
    "    )\n",
    "\n",
    "    return requests.get(url).json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fred_series_request(\"GDP\")\n",
    "df = pd.DataFrame(data[\"observations\"])\n",
    "df.to_csv(\"GDP.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pd.read_html`\n",
    "\n",
    "https://www.espn.com/soccer/schedule/_/league/ger.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def retrieve_soccer_schedule():\n",
    "    url = \"https://www.espn.com/soccer/schedule/_/league/ger.1\"\n",
    "\n",
    "    # Returns a list of tables -- We know that the first one\n",
    "    # is the one we want\n",
    "    return pd.read_html(url)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = retrieve_soccer_schedule()\n",
    "df.to_csv(\"soccer_schedule.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request intercept\n",
    "\n",
    "https://covid.cdc.gov/covid-data-tracker/#vaccinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def retrieve_vaccination_data():\n",
    "    url = \"https://covid.cdc.gov/covid-data-tracker/COVIDData/getAjaxData?id=vaccination_data\"\n",
    "\n",
    "    data = requests.get(url).json()\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def parse_vaccine_json_to_df(data):\n",
    "    df = pd.DataFrame(data[\"vaccination_data\"])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = retrieve_vaccination_data()\n",
    "df = parse_vaccine_json_to_df(data)\n",
    "df.to_csv(\"vaccination_data.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing page\n",
    "\n",
    "https://magicseaweed.com/Baltrum-Surf-Report/1117/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def retrieve_webpage_soup():\n",
    "    html = requests.get(\"https://magicseaweed.com/Baltrum-Surf-Report/1117/\").text\n",
    "    soup = BeautifulSoup(html)\n",
    "\n",
    "    return soup\n",
    "\n",
    "\n",
    "def extract_swell(soup):\n",
    "    list_group_items = soup.find_all(\"li\", attrs={\"class\": \"list-group-item\"})\n",
    "\n",
    "    rows = []\n",
    "    for item in list_group_items[:2]:\n",
    "        out = {}\n",
    "        out[\"variable\"] = item.find(\"div\", attrs={\"class\": \"list-group-title\"}).text.strip()\n",
    "        out[\"value\"] = item.find(\"div\", attrs={\"class\": \"list-group-content\"}).text.strip()\n",
    "        rows.append(out)\n",
    "\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = retrieve_webpage_soup()\n",
    "df = extract_swell(soup)\n",
    "\n",
    "df.to_csv(\"swell.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
